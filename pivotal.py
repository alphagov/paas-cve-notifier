import scrapy
import utils
from datetime import datetime


def serialize_date(value):
    """
    Serialize the string date to a datetime value.
    :param value:
    :return:
    """
    return datetime.strptime(value, '%d %b %Y')


class PivotalSpider(scrapy.Spider):
    utils.init_datadog()

    name = "pivotal_security"
    start_urls = ['https://pivotal.io/security']

    def parse(self, response):
        rows = response.css('table tr')
        entries = 0

        if len(rows) <= 0:
            utils.Report.warning()

        for cve in rows:
            fields = cve.css('td')

            try:
                date = serialize_date(utils.get_string(fields[0].css('::text').extract()))
            except ValueError:
                continue

            reference = utils.get_string(fields[2].css('a ::text').extract())
            url = utils.get_string(fields[2].xpath('a//@href').extract())
            description = utils.get_string(fields[4].css('::text').extract())

            if len(reference) > 0 and len(url) > 0:
                entries += 1

            # Check if the leak has been published today.
            if utils.midnight(datetime.today()) <= date:
                leak = {
                    'date': date,
                    'reference': reference,
                    'url': 'https://pivotal.io' + url,
                    'description': description
                }

                if not utils.event_exists(leak['reference']):
                    utils.send_event('pivotal', leak)

            if entries <= 0:
                utils.Report.critical()
