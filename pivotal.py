import scrapy
import utils
from datetime import datetime


def serialize_date(value):
    """
    Serialize the string date to a datetime value.
    :param value:
    :return:
    """
    return datetime.strptime(value, '%d %b %Y')


class PivotalSpider(scrapy.Spider):
    utils.init_datadog()

    name = "pivotal_security"
    start_urls = ['https://pivotal.io/security']

    def parse(self, response):
        rows = response.css('table tr')

        if len(rows) <= 0:
            utils.Report.warning()

        for cve in rows:
            fields = cve.css('td')

            try:
                date = serialize_date(utils.get_string(fields[0].css('::text').extract()))
            except ValueError:
                continue

            # Check if the leak has been published today.
            if utils.midnight(datetime(2016, 10, 20)) <= date:
                leak = {
                    'date': date,
                    'reference': utils.get_string(fields[2].css('a ::text').extract()),
                    'url': 'https://pivotal.io' + utils.get_string(fields[2].xpath('a//@href').extract()),
                    'description': utils.get_string(fields[4].css('::text').extract())
                }

                if not utils.event_exists(leak['reference'] + "-test"):
                    print("sent")
                    utils.send_event('pivotal', leak)
                else:
                    print("not sent")
